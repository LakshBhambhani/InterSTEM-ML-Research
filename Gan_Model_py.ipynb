{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport cv2\n \n# import cv2/numpy\n\n#cv2.UMath(file) number.32float(file)\n\nimport os\nfrom PIL import Image\nimage_files = []\nfor dirname, _, filenames in os.walk('/kaggle/input/gopro-deblur/'):\n    for filename in filenames:\n        file = os.path.join(dirname, filename)\n        image = Image.open(file)\n        print(file)\n        height = 220\n        width = 220\n        dim = (width, height)\n        res = cv2.resize(np.float32(image), dim, interpolation=cv2.INTER_LINEAR)\n        print(1)\n        \n\n# # Preprocessing\n# res_img = []\n# def processing():\n#     # loading image\n#     # Getting 3 images to work with \n  \n#     #print('Original size',img[0].shape)\n#     # --------------------------------\n#     # setting dim of the resize\n#     height = 220\n#     width = 220\n#     dim = (width, height)\n#     for files in image_files:\n#         print(files)\n#         res = cv2.resize('/kaggle/input/gopro-deblur/gopro-deblur/sharp/images'+ filename, dim, interpolation=cv2.INTER_LINEAR)\n#         print(1)\n#         #res_img.append(res)\n  \n#     # Checking the size\n#     #print(\"RESIZED\", res_img[0].shape)\n    \n#     # Visualizing one of the images in the array\n#     #original = res_img[1]\n#    #display_one(original)\n    \n    \n# processing()","execution_count":23,"outputs":[{"output_type":"stream","text":"/kaggle/input/gopro-deblur/gopro_deblur/sharp/images/000585.png\n","name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"could not convert string to float: '/kaggle/input/gopro-deblur/gopro_deblur/sharp/images/000585.png'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-4a45702f3692>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m220\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_LINEAR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: could not convert string to float: '/kaggle/input/gopro-deblur/gopro_deblur/sharp/images/000585.png'"]}]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"print(len(image_files))","execution_count":64,"outputs":[{"output_type":"stream","text":"2058\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n# Preprocessing\nres_img = []\ndef processing():\n    # loading image\n    # Getting 3 images to work with \n  \n    #print('Original size',img[0].shape)\n    # --------------------------------\n    # setting dim of the resize\n    height = 220\n    width = 220\n    dim = (width, height)\n    for files in image_files:\n        print(files)\n        res = cv2.resize('/kaggle/input/gopro-deblur/gopro-deblur/sharp/images'+ filename, dim, interpolation=cv2.INTER_LINEAR)\n        print(1)\n        #res_img.append(res)\n  \n    # Checking the size\n    #print(\"RESIZED\", res_img[0].shape)\n    \n    # Visualizing one of the images in the array\n    #original = res_img[1]\n   #display_one(original)\n    \n    \nprocessing()\n\n\n\n\n\n\n\n\n\n\n\n\n# Preprocessing\nres_img = []\ndef processing(data):\n    # loading image\n    # Getting 3 images to work with \n  \n    #print('Original size',img[0].shape)\n    # --------------------------------\n    # setting dim of the resize\n    height = 220\n    width = 220\n    dim = (width, height)\n    for files in data:\n        res = cv2.resize(files, dim, interpolation=cv2.INTER_LINEAR)\n        print(1)\n        res_img.append(res)\n  \n    # Checcking the size\n    print(\"RESIZED\", res_img[1].shape)\n    \n    # Visualizing one of the images in the array\n    original = res_img[1]\n    display_one(original)\n    \n    \nprocessing(image_files)","execution_count":2,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'image_files' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-839ebb8a24d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'image_files' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport glob\nimport imageio\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport PIL\nfrom tensorflow.keras import layers\nimport time\n\nfrom IPython import display\n","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":18,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"too many values to unpack (expected 2)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-0b2971e47091>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/input/gopro-deblur/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m127.5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m127.5\u001b[0m \u001b[0;31m# Normalize the images to [-1, 1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"BUFFER_SIZE = 60000\nBATCH_SIZE = 256","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_generator_model():\n    model = tf.keras.Sequential()\n    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Reshape((7, 7, 256)))\n    assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size\n\n    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n    assert model.output_shape == (None, 7, 7, 128)\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n    assert model.output_shape == (None, 14, 14, 64)\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n    assert model.output_shape == (None, 28, 28, 1)\n\n    return model","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":17,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"<matplotlib.image.AxesImage at 0x7f2020241490>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_discriminator_model():\n    model = tf.keras.Sequential()\n    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n                                     input_shape=[28, 28, 1]))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Flatten())\n    model.add(layers.Dense(1))\n\n    return model","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(res_img))","execution_count":29,"outputs":[{"output_type":"stream","text":"0\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"discriminator = make_discriminator_model()\ngenerated_image = res_img[0]\ndecision = discriminator(generated_image)\nprint (decision)","execution_count":27,"outputs":[{"output_type":"error","ename":"IndexError","evalue":"list index out of range","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-619803c7e0e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdiscriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_discriminator_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgenerated_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This method returns a helper function to compute cross entropy loss\ncross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def discriminator_loss(real_output, fake_output):\n    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n    total_loss = real_loss + fake_loss\n    return total_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generator_loss(fake_output):\n    return cross_entropy(tf.ones_like(fake_output), fake_output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generator_optimizer = tf.keras.optimizers.Adam(1e-4)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(1e-4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}